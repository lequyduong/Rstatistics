---
title: "Bayesian modeling and prediction for movies"
output: 
  html_document: 
    fig_height: 4
    highlight: pygments
    theme: spacelab
---

## Setup

### Load packages

```{r load-packages, message = FALSE}
library(ggplot2)
library(dplyr)
library(statsr)
library(BAS)
```

### Load data


```{r load-data}
load("movies.Rdata")
```



* * *

## Part 1: Data
Data collection: The data consists of 651 randomly selected movies which are also available from Rotten Tomatoes and IMDB. The 32 variables are specific parameters of the movies and people's opinion in the movies.
source of bias: There could be possible source of bias when choosing the movies which are available on Rotten Tomatoes and IMDB only. In addition, the bias on people's opinion is also possible

Generalization: Since random sampling was used with a reasonably large number of movies, the data does capture generalization.

Causation: This data is a result of observational study, there was no explicit random assignment. Hence, there is no causation in the data. 

* * *

## Part 2: Data manipulation

Creating new variables using the mutate function.

```{r}
movies <- movies %>%
  mutate(feature_film=ifelse(title_type == "Feature Film","yes","no")) %>%
  mutate(drama = ifelse(genre == "Drama", "yes", "no")) %>%
  mutate(mpaa_rating_R = ifelse(mpaa_rating == "R","yes","no")) %>%
  mutate(oscar_season = ifelse((thtr_rel_month == 11)|(thtr_rel_month == 10)|(thtr_rel_month == 12),"yes","no")) %>%
  mutate(summer_season = ifelse((thtr_rel_month == 5)|(thtr_rel_month == 6)|(thtr_rel_month == 7)|(thtr_rel_month == 8),"yes","no"))
  
```


* * *

## Part 3: Exploratory data analysis

```{r}
ggplot(data = movies, mapping = aes(x = audience_score, fill = feature_film)) + geom_histogram() + facet_grid(oscar_season ~.) 

```

Here, we show a feature film dependent histogram of audience score. It seems that no matter in which oscar season and feature film they are, the audience score follows the same tendency. 

```{r}
ggplot(data = movies, mapping = aes(x = audience_score, fill = drama)) + geom_histogram()

```

The figure shows audience score by drama. The audience score histogram obviously dominates when drama is no.

```{r}
ggplot(data = movies, mapping = aes(x = audience_score, fill = mpaa_rating_R)) + geom_histogram() 

```

Similarly, the audience score histogram is also larger when mpaa_rating_R is no.

```{r}
ggplot(data = movies, mapping = aes(x = imdb_rating, y = audience_score)) + geom_point() 

```

This is scatter plot of imdb_rating and audience_score. We expect a linear relationship between these two parameters, this could be easily fitted by a line.

```{r}
ggplot(data = movies, mapping = aes(x = critics_score, y = audience_score)) + geom_point() 

```

The plot of critics_score and audience_score are scattered, with a larger residuals.

```{r}
movies %>%
  summarise(mean_score=mean(audience_score),median_score=median(audience_score),sd_score=sd(audience_score),max_score=max(audience_score),min_score=min(audience_score))
```

EDA of the audience score, this quality is important as a response variable with mean 62.4 and standard deviation 20.2.


```{r}
movies %>%
  summarise(mean_critics=mean(critics_score),median_critics=median(critics_score),sd_critics=sd(critics_score),max_critics=max(critics_score),min_critics=min(critics_score))
  
```

Results for EDA of critics score.

```{r}
movies %>%
  summarise(mean_imdb=mean(imdb_rating),median_imdb=median(imdb_rating),sd_imdb=sd(imdb_rating),max_imdb=max(imdb_rating),min_imdb=min(imdb_rating))
  
```

EDA for imdb rating.

```{r}
movies %>%
  group_by(feature_film, drama,mpaa_rating_R) %>%
  summarise(count = n())

```

Summary statistics of movies by feature film, drama and mpaa_rating_R.

* * *

## Part 4: Modeling

Bayesan model averaging:

```{r bas-wage}
movies_no_na = na.omit(movies)
bma_movies = bas.lm(audience_score ~ feature_film + drama+runtime+mpaa_rating_R+thtr_rel_year+oscar_season+summer_season+imdb_rating+imdb_num_votes+critics_score+best_pic_nom+best_pic_win+best_actor_win+best_actress_win+best_dir_win+top200_box, data=movies_no_na,prior = "BIC", modelprior = uniform())
bma_movies
summary(bma_movies)
```

We show the summary of Bayesan model averaging. As discussed the intercept and imdb_rating has inclusion probability equal to 1. Meanwhile, almost all other parameters have non-negligible inclusion probability.


```{r vis-BMA}
par(mfrow = c(1,2))
coef_movies = coefficients(bma_movies)
plot(coef_movies, subset = c(4,5), ask=FALSE)
```

Plot shows coefficient of BMA model for runtime and mpaa_rating_R. We also probide 95% credible intervals for these coefficients:

```{r conf-BMA}
confint(coef_movies)
```

Use a Zellner-Siow null prior for the coefficients and a Beta-Binomial (1,1) prior for the models
```{r}
movies_no_na = na.omit(movies)
naive_movies = bas.lm(audience_score ~ feature_film + drama+runtime+mpaa_rating_R+thtr_rel_year+oscar_season+summer_season+imdb_rating+imdb_num_votes+critics_score+best_pic_nom+best_pic_win+best_actor_win+best_actress_win+best_dir_win+top200_box, data=movies_no_na,
                   prior = "ZS-null", 
                   modelprior = beta.binomial(1,1))
summary(naive_movies)

```

# Training the data

Similar to the codes in suplementary materials. We train the data using four different predictors and compare the efficiency of them:
  
```{r cv, cache=TRUE}
set.seed(42)

movies_no_na = na.omit(movies)

n = nrow(movies_no_na)
n_cv = 50
ape = matrix(NA, ncol=4, nrow=n_cv)
colnames(ape) = c("BMA", "BPM", "HPM", "MPM")

for (i in 1:n_cv) {
  train = sample(1:n, size=round(.90*n), replace=FALSE)
  lmovies_train = movies_no_na[train,] 
  lmovies_test = movies_no_na[-train,] # drop specific row in R
  
  bma_train_movies = bas.lm(audience_score ~ feature_film + drama+runtime+mpaa_rating_R+thtr_rel_year+oscar_season+summer_season+imdb_rating+imdb_num_votes+critics_score+best_pic_nom+best_pic_win+best_actor_win+best_actress_win+best_dir_win+top200_box, data=lmovies_train, prior="BIC", modelprior=uniform(), initprobs="eplogp")
  yhat_bma = predict(bma_train_movies, lmovies_test, estimator="BMA")$fit
  yhat_hpm = predict(bma_train_movies, lmovies_test, estimator="HPM")$fit
  yhat_mpm = predict(bma_train_movies, lmovies_test, estimator="MPM")$fit
  yhat_bpm = predict(bma_train_movies, lmovies_test, estimator="BPM")$fit
  ape[i, "BMA"] = cv.summary.bas(yhat_bma, lmovies_test$audience_score)
  ape[i, "BPM"] = cv.summary.bas(yhat_bpm, lmovies_test$audience_score)
  ape[i, "HPM"] = cv.summary.bas(yhat_hpm, lmovies_test$audience_score)
  ape[i, "MPM"] = cv.summary.bas(yhat_mpm, lmovies_test$audience_score)
}
```

Checking sensitivity the predictions are to the choice of estimator: We can see BMA is the best estimator.
```{r ape}
boxplot(ape)
apply(ape, 2, mean)
```
Here we compare the mean of all four type of predictors.


* * *

## Part 5: Prediction

Here I pick a movie from 2016 (a new movie that is not in the sample)
```{r new-prof}
newmovie <- data.frame(feature_film ="yes",drama = "yes", runtime = 120, mpaa_rating_R = "yes", thtr_rel_year = 2016, oscar_season = "yes", summer_season = "no", imdb_rating = 5.5, imdb_num_votes = 1000, critics_score = 96, best_pic_nom = "no", best_pic_win = "no", best_actor_win = "no", best_actress_win = "no", best_dir_win = "no", top200_box = "no")
```

We take the data for this movie randomly, and it does not exist in the data. However, we attempted to choose all the parameters in the data in an acceptable range, i.e between min and max of all parameters of interest.

Predict with confident level:
```{r}
#predict(bma_movies, newmovie, interval = "prediction", level = 0.95)
newmovies.pred <- predict(bma_movies, newdata=newmovie, estimator="BMA", se.fit=TRUE, interval="predict")
newmovies.pred$Ybma
```
Hence, we predict that newmovie hat an expected value of 49.57648

* * *

## Part 6: Conclusion

In this project we developed a linear model using Bayersan Model Averaging. All the parameters which were included are necessary to fit the model. Futher including the data of movies could give a more accurate prediction, since there is a lot of categorical variables in the original model.

